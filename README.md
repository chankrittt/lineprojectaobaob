# Drive2 - AI-Powered LINE Storage System

à¸„à¸¥à¹‰à¸²à¸¢ Google Drive à¹à¸•à¹ˆà¹€à¸à¹‡à¸šà¹„à¸Ÿà¸¥à¹Œà¸šà¸™ LINE à¹à¸¥à¸°à¹ƒà¸Šà¹‰ AI à¸ˆà¸±à¸”à¸à¸²à¸£à¹„à¸Ÿà¸¥à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´

## Features

- **Easy Upload**: à¸ªà¹ˆà¸‡à¹„à¸Ÿà¸¥à¹Œà¸œà¹ˆà¸²à¸™ LINE Group à¸•à¸²à¸¡à¸›à¸à¸•à¸´
- **Smart Naming**: AI à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¹ƒà¸«à¹‰à¸ªà¸·à¹ˆà¸­à¸„à¸§à¸²à¸¡à¸«à¸¡à¸²à¸¢
- **Auto Tag & Summarize**: AI à¸ªà¸£à¸¸à¸›à¹à¸¥à¸°à¸•à¸´à¸”à¹à¸—à¹‡à¸à¹„à¸Ÿà¸¥à¹Œ
- **Semantic Search**: à¸„à¹‰à¸™à¸«à¸²à¹„à¸Ÿà¸¥à¹Œà¸”à¹‰à¸§à¸¢ AI (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ˆà¸³à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œ)
- **No Login Required**: à¹ƒà¸Šà¹‰ LINE Official Account

## Tech Stack

### Backend
- **FastAPI** - Python web framework
- **PostgreSQL** - Main database
- **Redis** - Cache & Queue
- **Qdrant** - Vector database for semantic search
- **MinIO** - S3-compatible object storage
- **Gemini AI** - File analysis & embeddings

### Frontend
- **Next.js** - React framework
- **LINE LIFF** - LINE Frontend Framework

## Prerequisites

- Python 3.11+
- Docker & Docker Compose
- MinIO server (running at 172.27.15.49)
- LINE Official Account
- Gemini API Key

## Quick Start

### 1. Clone & Setup

```bash
cd drive2
```

### 2. Configure Environment

```bash
# Copy example env file
cp .env.example .env

# Edit .env and fill in your credentials:
# - MINIO_ACCESS_KEY
# - MINIO_SECRET_KEY
# - GEMINI_API_KEY
# - LINE_CHANNEL_SECRET
# - LINE_CHANNEL_ACCESS_TOKEN
# - LINE_LIFF_ID
```

### 3. Start Infrastructure

```bash
# Start PostgreSQL, Redis, Qdrant
docker-compose up -d

# Check if all services are running
docker-compose ps
```

### 4. Install Python Dependencies

```bash
cd backend
pip install -r requirements.txt
```

### 5. Test Connections

```bash
# Test all service connections
python test_connections.py
```

Expected output:
```
âœ… PostgreSQL: Connected successfully
âœ… Redis: Connected successfully
âœ… Qdrant: Connected successfully
âœ… MinIO: Connected successfully
âœ… Gemini API: Connected successfully
ğŸ‰ All services connected successfully!
```

### 6. Run Database Migrations

```bash
# Create initial migration
alembic revision --autogenerate -m "Initial migration"

# Run migrations
alembic upgrade head
```

### 7. Start Development Server

```bash
# Start FastAPI
python main.py

# Or use uvicorn directly
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Visit:
- API Docs: http://localhost:8000/docs
- Qdrant Dashboard: http://localhost:6333/dashboard

## Project Structure

```
drive2/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ endpoints/      # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py       # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ database.py     # Database connection
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ database.py     # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ai_service.py       # Gemini AI
â”‚   â”‚   â”‚   â”œâ”€â”€ storage_service.py  # MinIO
â”‚   â”‚   â”‚   â””â”€â”€ vector_service.py   # Qdrant
â”‚   â”‚   â””â”€â”€ schemas/            # Pydantic schemas
â”‚   â”œâ”€â”€ alembic/                # Database migrations
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ test_connections.py
â”œâ”€â”€ frontend/                   # LINE LIFF app (Next.js)
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## Services

### PostgreSQL
- **Port**: 5432
- **Database**: drive2_db
- **User**: drive2_user
- **Password**: drive2_password (change in .env)

### Redis
- **Port**: 6379
- **DB 0**: Cache
- **DB 1**: Celery queue

### Qdrant
- **Port**: 6333 (HTTP API)
- **Port**: 6334 (gRPC)
- **Dashboard**: http://localhost:6333/dashboard

### MinIO
- **External**: http://172.27.15.49:9000
- **Bucket**: drive2-files

## Development

### Run Tests
```bash
cd backend
pytest
```

### Check Logs
```bash
# View Docker logs
docker-compose logs -f

# Specific service
docker-compose logs -f postgres
docker-compose logs -f redis
docker-compose logs -f qdrant
```

### Stop Services
```bash
# Stop all Docker containers
docker-compose down

# Stop and remove volumes (âš ï¸ deletes data)
docker-compose down -v
```

## API Endpoints (Planned)

### Authentication
- `POST /api/v1/auth/line` - LINE Login

### Files
- `GET /api/v1/files` - List files
- `POST /api/v1/files/upload` - Upload file
- `GET /api/v1/files/:id` - Get file details
- `PUT /api/v1/files/:id` - Update file
- `DELETE /api/v1/files/:id` - Delete file
- `GET /api/v1/files/:id/download` - Download file

### Search
- `POST /api/v1/search/semantic` - Semantic search
- `GET /api/v1/search/text` - Full-text search

### Collections
- `GET /api/v1/collections` - List collections
- `POST /api/v1/collections` - Create collection
- `POST /api/v1/collections/:id/files/:fileId` - Add file to collection

### Webhook
- `POST /api/v1/webhook/line` - LINE webhook

## Troubleshooting

### MinIO Connection Failed
```bash
# Check if MinIO is accessible
curl http://172.27.15.49:9000

# Verify credentials in .env file
```

### PostgreSQL Connection Failed
```bash
# Check if container is running
docker-compose ps postgres

# Restart PostgreSQL
docker-compose restart postgres
```

### Gemini API Failed
```bash
# Verify API key is correct
# Check quota: https://aistudio.google.com/app/apikey
```

## Next Steps

1. Implement API endpoints (files, search, collections)
2. Create Celery workers for background jobs
3. Build LINE webhook handler
4. Develop LIFF frontend
5. Add authentication & authorization
6. Implement file processing pipeline

## License

MIT

## Contact

Issues: Create an issue on GitHub
